
BASE_URL=https://api.deepseek.com/v1
# In case of using Docker Model Runner: http://host.docker.internal:12434/engines/v1

# Here enter the API Key from your LLM provider
LLM_API_KEY=your-api-key
# In case of using Docker Model Runner it can be anything

MODEL=deepseek-chat
# For development I used this model from the ai Docker Hub: ai/ministral3:latest

DATABASE_URL=sqlite+aiosqlite:///./trupy.db

REDIS_URL=redis://redis:6379/0

SESSION_TTL=900

RATE_LIMIT_CHAT=15/minute